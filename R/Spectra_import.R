#'Constructs a dataSet object for storing data 
#'@description This functions handles the construction of a mSetObj object for storing data for further processing and analysis.
#'It is necessary to utilize this function to specify to MetaboAnalystR the type of data and the type of analysis you will perform. 
#'@usage InitDataObjects(data.type, anal.type, paired=FALSE)
#'@param data.type The type of data, either list (Compound lists), conc (Compound concentration data), 
#'specbin (Binned spectra data), pktable (Peak intensity table), nmrpeak (NMR peak lists), mspeak (MS peak lists), 
#'or msspec (MS spectra data)
#'@param anal.type Indicate the analysis module to be performed: stat, pathora, pathqea, msetora, msetssp, msetqea, ts, 
#'cmpdmap, smpmap, or pathinteg
#'@param paired Indicate if the data is paired or not. Logical, default set to FALSE
#'@author Jeff Xia \email{jeff.xia@mcgill.ca}
#'McGill University, Canada
#'License: GNU GPL (>= 2)
#' @export
#' @import methods
#' @import BiocParallel
#' @importFrom  Cairo CairoFonts
#' @examples 
#' library(OptiLCMS);
#' mSet<-InitDataObjects("spec", "raw", FALSE)

InitDataObjects <- function(data.type, anal.type, paired=FALSE){
  
  if(anal.type == "raw" & data.type == "spec") {
    MessageOutput("OptiLCMS R objects initialized ...\n");
    return(new("mSet"))
  }
  
}

#' Import raw MS data
#' @description This function handles the reading in of
#' raw MS data (.mzML, .CDF and .mzXML). Users must set
#' their working directory to the folder containing their raw
#' data, divided into two subfolders named their desired group labels. The
#' function will output two chromatograms into the user's working directory, a
#' base peak intensity chromatogram (BPIC) and a total ion
#' chromatogram (TIC). Further, this function sets the number of cores
#' to be used for parallel processing. It first determines the number of cores
#' within a user's computer and then sets it that number/2.
#' @param mSet mSet Object, can be optional. Usually generated by InitDataObjects("spec", "raw", FALSE) before the data import.
#' @param path Character, input the path to the folder containing
#' the raw MS spectra to be processed. Or a character vector containing all raw files absolute paths.
#' @param metadata Data.frame or character. A phenotype data frame or a absolute path of the metadata file (.txt) for all samples, optional. 
#' In the option, first column should be the sample name, while second column is the corresponding group name. If ommited, all samples in the same sub-folder will be 
#' considered as one group.
#' @param mode Character, the data input mode. Default is "onDisk" to avoid memory crash. "inMemory" will
#' read data into memory.
#' @param plotSettings List, plotting parameters produced by SetPlotParam Function. "plot.opts" can be added through this
#' function for samples numbers for plotting. Defalut is "default", "all" will apply all samples for plotting and may cause
#' memory crash, especially for large sample dataset.
#' @param running.controller The resuming pipeline running controller. Optional. Don't need to define by hand.
#' @author Zhiqiang Pang \email{zhiqiang.pang@mail.mcgill.ca}, Jasmine Chong \email{jasmine.chong@mail.mcgill.ca},
#' Mai Yamamoto \email{yamamoto.mai@mail.mcgill.ca}, and Jeff Xia \email{jeff.xia@mcgill.ca}
#' McGill University, Canada
#' License: GNU GPL (>= 2)
#' @export
#' @import MSnbase
#' @import BiocParallel
#' @import parallel
#' @importFrom tools file_path_as_absolute file_ext
#' @importFrom Cairo Cairo
#' @examples 
#' ## load googledrive package to download example data
#' ##' Load OptiLCMS package
#' library(OptiLCMS)
#' ##' Get raw spectra files
#' DataFiles <- dir(system.file("mzData", package = "mtbls2"), full.names = TRUE,
#'                  recursive = TRUE)[c(10:12, 14:16)]
#' ##' Create a phenodata data.frame
#' pd <- data.frame(sample_name = sub(basename(DataFiles), pattern = ".mzData",
#'                                    replacement = "", fixed = TRUE),
#'                  sample_group = c(rep("col0", 3), rep("cyp79", 3)),
#'                  stringsAsFactors = FALSE)
#' ##' Import raw spectra
#' mSet <- ImportRawMSData(path = DataFiles, metadata = pd);

ImportRawMSData <-
  function(mSet = NULL,
           path = getwd(),
           metadata = NULL,
           mode = "onDisk",
           plotSettings = SetPlotParam(),
           running.controller = NULL) {
    
    #Initialize a new mSet if missing
    if(missing(mSet)){
      message("No initialized mSet found, will initialize one automatically !")
      mSet <- new("mSet")
    } else if(is.null(mSet)){
      message("Not a real initialized mSet found, will re-initialize one automatically !")
      mSet <- new("mSet")
    }
    
    #Build Running plan for data import - Indentify the controller
    if (is.null(running.controller)) {
      c1 <- TRUE;
      c2 <- TRUE;
      plan_switch <- FALSE;
    } else {
      plan_switch <- TRUE;
      c1 <-
        running.controller@data_import[["c1"]] # used to control data import
      c2 <-
        running.controller@data_import[["c2"]] # used to control plotting option
    }
    
    if(!exists(".SwapEnv")){
      .SwapEnv <<- new.env(parent = .GlobalEnv);
      .SwapEnv$.optimize_switch <- FALSE;
      .SwapEnv$count_current_sample <- 0;
      .SwapEnv$count_total_sample <- 120; # maximum number for on.public.web
      .SwapEnv$envir <- new.env();
    }
    .SwapEnv$.optimize_switch <- FALSE;
    
    start.time <- Sys.time()
    
    ## Deal with the different file path cases
    files <- Path2Files(path = path);
    
    if (length(files) == 0) {
      MessageOutput(
        mes = paste0(
          "<font color=\"red\">",
          "\nERROR: No standard MS file found ! Please check the extension of your data.",
          "</font>"
        ),
        ecol = "\n",
        progress = NULL
      )
      stop()
      
    } else if (length(files) < 3) {
      MessageOutput(
        mes = paste0(
          "<font color=\"red\">",
          "\nERROR: At least 3 samples should be provided.",
          "</font>"
        ),
        ecol = "\n",
        progress = NULL
      )
    }
    
    .SwapEnv$count_total_sample <- length(files);
    .SwapEnv$count_current_sample <- 0;
    toRemove = vector();
    
    # Update first
    if(length(mSet@rawfiles) == 0){
      rawfilenms <- basename(files);
    } else {
      rawfilenms <- basename(mSet@rawfiles);
    }
    
    for (i in 1:length(files)) {
      file = basename(files[i])
      if (!(file %in% rawfilenms)) {
        toRemove = c(toRemove, files[i])
      }
    }
    
    toKeepInx = !(files %in% toRemove);
    files = files[toKeepInx];
    
    ####### -------------- Files ready ------------------#
    
    if(missing(metadata) | is.null(metadata)){
      warning("No metadata provided, all files in one sub-folder will be considered a group!")
    
      snames <- gsub("\\.[^.]*$", "", basename(files))
      # msg <- c(msg, paste("A total of ", length(files), "samples were found."))
      sclass <- gsub("^\\.$", "sample", dirname(files))
      
      scomp <- strsplit(substr(sclass, 1, min(nchar(sclass))), "", fixed = TRUE)
      scomp <- matrix(c(scomp, recursive = TRUE), ncol = length(scomp))
      
      i <- 1
      while (all(scomp[i, 1] == scomp[i, -1]) && i < nrow(scomp)) {
        i <- i + 1
      }
      
      i <-
        min(i, tail(c(0, which(
          scomp[1:i, 1] == .Platform$file.sep
        )), n = 1) + 1)
      
      if (i > 1 && i <= nrow(scomp)) {
        sclass <- substr(sclass, i, max(nchar(sclass)))
      }
      
      if (.on.public.web &
          unique(sclass)[1] == "upload" &
          length(unique(sclass)) == 1) {
        sclass <- rep("Unknown", length(sclass))
      }

    } else if(is.data.frame(metadata)) {
      metadata <- metadata;
    } else if(is.character(metadata)){
      metadata <- read.table(metadata)
    }
    
    filesNM <- sub(pattern = "(.*)\\..*$", replacement = "\\1", basename(files));
    
    if(!all(basename(files) %in% metadata[,1])){
      if(!all(basename(filesNM) %in% metadata[,1])){
        warning("More files detected than metadata, will omit the extra files not in metadata!")
      }
    }
    
    snames <- metadata[metadata[,1] %in% c(basename(files), filesNM), 1]
    sclass <- metadata[metadata[,1] %in% c(basename(files), filesNM), 2]
    
    if(length(snames) == 0 | length(sclass) == 0){
      stop("No correct sample/sclass found!")
    }
    
    pd <- data.frame(
      sample_name = snames,
      sample_group = sclass,
      stringsAsFactors = FALSE
    )

    
    
    MessageOutput(mes = "\nStep 2/6: Start to import the spectrum! \nThis step will take a short time...",
                  ecol = "\n",
                  progress = 21.0)
    
    
    if (c1) {
      raw_data <-
        suppressMessages(read.MSdata(
          files = files,
          pdata = new("NAnnotatedDataFrame", pd),
          mode = mode,
          msLevel. = 1
        ))
      
      if(plan_switch){
        cache.save(raw_data, funpartnm = "data_import_c1");
        marker_record("data_import_c1");
      }
 
    } else {
      raw_data <- cache.read ("data_import", "c1")
      marker_record("data_import_1")
    }
    
    MessageOutput(NULL, NULL, 22)
    
    if (c2) {
      if (plotSettings$Plot == TRUE) {
        if (is.null(plotSettings$plot.opts)) {
          plot.opts <- "default"
        } else {
          plot.opts <- plotSettings$plot.opts
        }
        
        if (plot.opts == "default") {
          #subset raw_data to first 50 samples
          MessageOutput("To reduce memory usage BPIS and TICS plots will be created using only 10 samples per group.")
          
          grp_nms <- names(table(pd$sample_group))
          files <- NA
          
          for (i in 1:length(grp_nms)) {
            numb2ext <- min(table(pd$sample_group)[i], 10)
            filt_df <- pd[pd$sample_group == grp_nms[i], ]
            files.inx <- sample(nrow(filt_df), numb2ext)
            sel.samples <- filt_df$sample_name[files.inx]
            files <-
              c(files, which(pd$sample_name %in% sel.samples))
          }
          
          raw_data_filt <-
            filterFile(raw_data, file = na.omit(files))
          
        } else{
          raw_data_filt <- raw_data
          # just for plotting
        }
        
        if (plot.opts == "all") {
          h <-
            readline(prompt = "Using all samples to create BPIS and TICS plots may cause severe memory issues! Press [0] to continue, or [1] to cancel: ")
          h <- as.integer(h)
          
          if (h == 1) {
            MessageOutput("ImportRawMSData function aborted!\n")
            return(0)
          }
        }
        
        MessageOutput("Plotting BPIS and TICS.")
        # Plotting functions to see entire chromatogram
        bpis <- chromatogram(raw_data_filt, aggregationFun = "max")
        tics <- chromatogram(raw_data_filt, aggregationFun = "sum")
        groupInfo <-as.factor(pd$sample_group);
        groupNum <- nlevels(groupInfo)
        
        if (groupNum > 9) {
          col.fun <-
            grDevices::colorRampPalette(RColorBrewer::brewer.pal(12, "Set3"))
          group_colors <- col.fun(groupNum)
          
        } else{
          group_colors <-
            paste0(RColorBrewer::brewer.pal(9, "Set1")[1:groupNum], "60")
        }
        
        names(group_colors) <- levels(groupInfo)
        
        bpis_name <-
          paste("BPIS_",
                plotSettings$dpi,
                ".",
                plotSettings$format,
                sep = "")
        
        tics_name <-
          paste("TICS_",
                plotSettings$dpi,
                ".",
                plotSettings$format,
                sep = "")
        
        #save(bpis, file = "bpis.rda"); # Don't need bpis for now.
        if(.on.public.web){
          save(raw_data_filt, file = "raw_data_filt.rda");
          save(tics, file = "tics.rda");
        }
        
        if (.on.public.web) {
          Cairo::Cairo(
            file = bpis_name,
            unit = "in",
            dpi = plotSettings$dpi,
            width = 8,
            height = 6,
            type = plotSettings$format,
            bg = "white"
          )
        }
        
        plot(bpis, col = group_colors[raw_data_filt$sample_group])
        legend(
          "topright",
          legend = levels(groupInfo),
          pch = 15,
          col = group_colors
        )
        
        if (.on.public.web) {
          dev.off()
          
          Cairo::Cairo(
            file = tics_name,
            unit = "in",
            dpi = plotSettings$dpi,
            width = 8,
            height = 6,
            type = plotSettings$format,
            bg = "white"
          )
        }
        
        plot(tics, col = group_colors[raw_data_filt$sample_group])
        legend(
          "topright",
          legend = levels(groupInfo),
          pch = 15,
          col = group_colors
        )
        
        if (.on.public.web) {
          dev.off()
        }
        
      }
      if (plan_switch) {
        marker_record("data_import_c2")
      }
    }
    
    MessageOutput(
      mes = paste0(
        "Step 2/6: Successfully imported raw MS data! (",
        Sys.time(),
        ") \nGoing to the next step..."
      ),
      ecol = "\n",
      progress = 24
    )
    
    if(mode == "onDisk"){
      mSet@rawOnDisk <- raw_data;
    } else if( mode == "inMemory"){
      mSet@rawInMemory <- raw_data;
    }
      
    return(mSet)
  }

read.MSdata <- function(files, 
                        pdata = NULL, 
                        msLevel. = NULL, 
                        centroided. = NA,
                        smoothed. = NA, 
                        cache. = 1L,
                        mode = c("inMemory", "onDisk")) {
  
  mode <- match.arg(mode)
  ## o normalize the file path, i.e. replace relative path with absolute
  ##   path. That fixes possible problems on Windows with SNOW parallel
  ##   processing and also proteowizard problems on unis system with ~ paths.
  files <- normalizePath(files)
  suppressWarnings(.hasChroms <- MSnbase::hasChromatograms(files))
  
  MessageOutput ("Raw file import begin...", "\n", NULL)
  
  if (!length(files)) {
    process <- new("MSnProcess",
                   processing = paste("No data loaded:", date()))
    if (mode == "inMemory")
      res <- new("MSnExp",
                 processingData = process)
    else res <- new("OnDiskMSnExp",
                    processingData = process)
  } else {
    if (mode == "inMemory") {
      if (is.null(msLevel.)) msLevel. <- 2L
      res <- read.InMemMSd.data(files, pdata = pdata, msLevel. = msLevel.,
                                centroided. = centroided., smoothed. = smoothed., cache. = cache.)
    } else { ## onDisk
      res <- read.OnDiskMS.data(files = files, pdata = pdata,
                                msLevel. = msLevel., centroided. = centroided., smoothed. = smoothed.)
    }
  }
  res
}

#' @import utils
read.InMemMSd.data <- function(files, 
                               pdata, 
                               msLevel., 
                               centroided., 
                               smoothed., 
                               cache. = 1) {
  .testReadMSDataInput(environment())
  if (isCdfFile(files)) {
    #message("Polarity can not be extracted from netCDF files, please set ",
    #        "manually the polarity with the 'polarity' method.")
    msLevel. <- 1;
  }
  
  if (msLevel. == 1) cache. <- 0
  msLevel. <- as.integer(msLevel.)
  ## Creating environment with Spectra objects
  assaydata <- new.env(parent = emptyenv())
  ioncount <- c()
  ioncounter <- 1
  filenams <- filenums <- c()
  fullhd2 <- fullhdorder <- c()
  fullhdordercounter <- 1
  .instrumentInfo <- list()
  ## List eventual limitations
  
  ## ## Idea:
  ## ## o initialize a featureData-data.frame,
  ## ## o for each file, extract header info and put that into
  ##      featureData;
  
  count.idx <- 0;
  
  for (f in files) {
    MessageOutput(paste("Reading MS from",basename(f),"..."))
    
    filen <- match(f, files)
    filenums <- c(filenums, filen)
    filenams <- c(filenams, f)
    ## issue #214: define backend based on file format.
    msdata <- mzR::openMSfile(f,backend = NULL)
    .instrumentInfo <- c(.instrumentInfo, list(mzR::instrumentInfo(msdata)))
    fullhd <- mzR::header(msdata)
    ## Issue #325: get centroided information from file, but overwrite if
    ## specified with centroided. parameter.
    if (!is.na(centroided.))
      fullhd$centroided <- as.logical(centroided.)
    spidx <- which(fullhd$msLevel == msLevel.)
    ## increase vectors as needed
    ioncount <- c(ioncount, numeric(length(spidx)))
    fullhdorder <- c(fullhdorder, numeric(length(spidx)))
    if (msLevel. == 1) {
      if (length(spidx) == 0)
        stop("No MS1 spectra in file",f)
      
      
      if (.on.public.web){   
        print_mes <- paste0("Importing ",basename(f),":");    
        write.table(print_mes,file="metaboanalyst_spec_proc.txt",append = TRUE,row.names = FALSE,col.names = FALSE, quote = FALSE, eol = " ");
      }
      else {
        pb <- progress_bar$new(format = "Reading [:bar] :percent Time left: :eta", 
                               total = length(spidx), clear = TRUE, width= 75)
      }
      
      k_count <- 0;
      for (i in 1:length(spidx)) {
        
        if (!.on.public.web){   
          pb$tick();
        }
        
        if (.on.public.web){  
          if (round(i/length(spidx),digits = 4)*100 - k_count > -0.2){
            print_mes <- paste0(k_count,"% | ");    
            write.table(print_mes,file="metaboanalyst_spec_proc.txt",append = TRUE,row.names = FALSE,col.names = FALSE, quote = FALSE, eol = " ");
            k_count <- k_count +20;
          }
          
        }
        
        j <- spidx[i]
        hd <- fullhd[j, ]
        ## Fix missing polarity from netCDF
        pol <- hd$polarity
        if (length(pol) == 0)
          pol <- NA
        .p <- mzR::peaks(msdata, j)
        sp <- new("Spectrum1",
                  rt = hd$retentionTime,
                  acquisitionNum = as.integer(hd$acquisitionNum),
                  scanIndex = as.integer(hd$seqNum),
                  tic = hd$totIonCurrent,
                  mz = .p[, 1],
                  intensity = .p[, 2],
                  fromFile = as.integer(filen),
                  centroided = as.logical(hd$centroided),
                  smoothed = as.logical(smoothed.),
                  polarity = as.integer(pol))
        ## peaksCount
        ioncount[ioncounter] <- sum(.p[, 2])
        ioncounter <- ioncounter + 1
        .fname <- formatFileSpectrumNames(
          fileIds = filen,
          spectrumIds = i,
          nSpectra = length(spidx),
          nFiles = length(files)
        )
        assign(.fname, sp, assaydata)
        fullhdorder[fullhdordercounter] <- .fname
        fullhdordercounter <- fullhdordercounter + 1
      }
    } else { ## .msLevel != 1
      if (length(spidx) == 0)
        stop("No MS(n>1) spectra in file", f)
      MessageOutput(paste("Reading ", length(spidx), " MS", msLevel.,
                          " spectra from file ", basename(f),"\n"))
      
      scanNums <- fullhd[fullhd$msLevel == msLevel., "precursorScanNum"]
      if (length(scanNums) != length(spidx))
        stop("Number of spectra and precursor scan number do not match!")
      
      pb <- progress_bar$new(format = "Reading [:bar] :percent Time left: :eta", 
                             total = length(spidx), clear = TRUE, width= 75)
      
      for (i in 1:length(spidx)) {
        
        pb$tick();
        
        j <- spidx[i]
        hd <- fullhd[j, ]
        .p <- mzR::peaks(msdata, j)
        sp <- new("Spectrum2",
                  msLevel = as.integer(hd$msLevel),
                  merged = as.numeric(hd$mergedScan),
                  precScanNum = as.integer(scanNums[i]),
                  precursorMz = hd$precursorMZ,
                  precursorIntensity = hd$precursorIntensity,
                  precursorCharge = as.integer(hd$precursorCharge),
                  collisionEnergy = hd$collisionEnergy,
                  rt = hd$retentionTime,
                  acquisitionNum = as.integer(hd$acquisitionNum),
                  scanIndex = as.integer(hd$seqNum),
                  tic = hd$totIonCurrent,
                  mz = .p[, 1],
                  intensity = .p[, 2],
                  fromFile = as.integer(filen),
                  centroided = as.logical(hd$centroided),
                  smoothed = as.logical(smoothed.),
                  polarity = as.integer(hd$polarity))
        ## peaksCount
        ioncount[ioncounter] <- sum(.p[, 2])
        ioncounter <- ioncounter + 1
        .fname <- formatFileSpectrumNames(
          fileIds = filen,
          spectrumIds = i,
          nSpectra = length(spidx),
          nFiles = length(files)
        )
        assign(.fname, sp, assaydata)
        fullhdorder[fullhdordercounter] <- .fname
        fullhdordercounter <- fullhdordercounter + 1
      }
    }
    if (cache. >= 1)
      fullhd2 <- rbind(fullhd2, fullhd[spidx, ])
    
    gc()
    mzR::close(msdata)
    rm(msdata);
    
    if (.on.public.web){ 
      print_mes <- paste0("Done!");    
      write.table(print_mes,file="metaboanalyst_spec_proc.txt",append = TRUE,row.names = FALSE,col.names = FALSE, quote = FALSE, eol = "\n");
      
      count.idx <- count.idx + 1;  
      write.table(1.0 + count.idx/length(files)*3, file = "log_progress.txt", row.names = FALSE,col.names = FALSE);
    }
    
    MessageOutput(paste0("Reading from ", basename(f), " finished successfully !"));
    
  }
  
  ## cache level 2 yet implemented
  cache. <- testCacheArg(cache., maxCache = 2)
  if (cache. >= 1) {
    fl <- sapply(assaydata, function(x) x@fromFile)
    featnms <- ls(assaydata) ## feature names in final MSnExp
    fl <- fl[featnms] ## reorder file numbers
    stopifnot(all(base::sort(featnms) == base::sort(fullhdorder)))
    fullhdorder <- match(featnms, fullhdorder)
    tmphd <- fullhd2[fullhdorder, ] ## reorder
    ioncount <- ioncount[fullhdorder]
    newhd <- data.frame(fileIdx = fl,
                        retention.time = tmphd$retentionTime,
                        precursor.mz = tmphd$precursorMZ,
                        precursor.intensity = tmphd$precursorIntensity,
                        charge = tmphd$precursorCharge,
                        peaks.count = tmphd$peaksCount,
                        tic = tmphd$totIonCurrent,
                        ionCount = ioncount,
                        ms.level = tmphd$msLevel,
                        acquisition.number = tmphd$acquisitionNum,
                        collision.energy = tmphd$collisionEnergy)
  } else {
    newhd <- NULL ## not used anyway
  }
  .cacheEnv <- setCacheEnv(list("assaydata" = assaydata,
                                          "hd" = newhd),
                                     cache., lock = TRUE)
  ## CACHING AS BEEN SUPERSEDED BY THE OnDiskMSnExp IMPLEMENTATION
  ## if cache==2, do not lock assign msdata in .cacheEnv then lock
  ## it and do not close(msdata) above; rm(msdata) is OK
  
  ## Create 'MSnProcess' object
  process <- new("MSnProcess",
                 processing = paste("Data loaded:", date()),
                 files = files,
                 smoothed = smoothed.)
  ## Create 'fdata' and 'pdata' objects
  nms <- ls(assaydata)
  if (is.null(pdata)) {
    .pd <- data.frame(sampleNames = basename(files))
    rownames(.pd) <- .pd$sampleNames
    pdata <- new("AnnotatedDataFrame",
                 data = .pd)
  }
  fdata <- new("AnnotatedDataFrame",
               data = data.frame(
                 spectrum = 1:length(nms),
                 row.names = nms))
  fdata <- fdata[ls(assaydata)] ## reorder features
  ## expriment data slot
  if (length(.instrumentInfo) > 1) {
    cmp <- length(unique(sapply(.instrumentInfo, "[[", 1)))
    if (cmp > 1)
      message("According to the instrument information in the files,\n",
              "the data has been acquired on different instruments!")
    for (nm in names(.instrumentInfo[[1]]))
      .instrumentInfo[[1]][[nm]] <- sapply(.instrumentInfo, "[[", nm)
  }
  expdata <- new("MIAPE",
                 instrumentManufacturer = .instrumentInfo[[1]]$manufacturer,
                 instrumentModel = .instrumentInfo[[1]]$model,
                 ionSource = .instrumentInfo[[1]]$ionisation,
                 analyser = as.character(.instrumentInfo[[1]]$analyzer),
                 detectorType = .instrumentInfo[[1]]$detector)
  ## Create and return 'MSnExp' object
  
  toReturn <- new("MSnExp",
                  assayData = assaydata,
                  phenoData = pdata,
                  featureData = fdata,
                  processingData = process,
                  experimentData = expdata,
                  .cache = .cacheEnv)
  return(toReturn)
}

read.OnDiskMS.data <- function(files, 
                               pdata, 
                               msLevel., 
                               centroided., 
                               smoothed.) {
  
  .testReadMSDataInput(environment())
  stopifnot(is.logical(centroided.))
  
  ## Creating environment with Spectra objects
  assaydata <- new.env(parent = emptyenv())
  filenams <- filenums <- c()
  fullhd2 <- fullhdorder <- c()
  fullhdordercounter <- 1
  .instrumentInfo <- list()
  ## List eventual limitations
  if (isCdfFile(files)) {
    message("Polarity can not be extracted from netCDF files, please set ",
            "manually the polarity with the 'polarity' method.")
  }
  ## Idea:
  ## o initialize a featureData-data.frame,
  featureDataList <- list()
  ## o for each file, extract header info and put that into featureData
  ##pb <- progress_bar$new(format = "Reading [:bar] :percent Time left: :eta", 
  #                       total = length(spidx), clear = TRUE, width= 75);
  
  count_mark <- 0;
  
  for (f in files) {
    
    if (.on.public.web){
      
      print_mes <- paste(basename(f),"import done!");    
      write.table(print_mes,file="metaboanalyst_spec_proc.txt",append = TRUE,row.names = FALSE,col.names = FALSE, quote = FALSE, eol = "\n");
      
    } else {
      #pb$tick();
    }    
    
    filen <- match(f, files)
    filenums <- c(filenums, filen)
    filenams <- c(filenams, f)
    ## issue #214: define backend based on file format.
    msdata <- mzR::openMSfile(f,backend = NULL)
    .instrumentInfo <- c(.instrumentInfo, list(mzR::instrumentInfo(msdata)))
    fullhd <- mzR::header(msdata)
    spidx <- seq_len(nrow(fullhd))
    
    ## Don't read the individual spectra, just define the names of
    ## the spectra.
    fullhdorder <- c(
      fullhdorder,
      formatFileSpectrumNames(
        fileIds = filen,
        spectrumIds = seq_along(spidx),
        nSpectra = length(spidx),
        nFiles = length(files)
      )
    )
    ## Extract all Spectrum info from the header and put it into the featureData
    fdData <- fullhd[spidx, , drop = FALSE]
    ## rename totIonCurrent and peaksCount, as detailed in
    ## https://github.com/lgatto/MSnbase/issues/105#issuecomment-229503816
    names(fdData) <- sub("peaksCount", "originalPeaksCount", names(fdData))
    ## Add also:
    ## o fileIdx -> links to fileNames property
    ## o spIdx -> the index of the spectrum in the file.
    fdData <- cbind(fileIdx = rep(filen, nrow(fdData)),
                    spIdx = spidx,
                    smoothed = rep(as.logical(smoothed.), nrow(fdData)),
                    fdData, stringsAsFactors = FALSE)
    if (isCdfFile(f)) {
      ## Add the polarity columns if missing in netCDF
      if (!any(colnames(fdData) == "polarity"))
        fdData <- cbind(fdData, polarity = rep(as.integer(NA),
                                               nrow(fdData)))
    }
    ## Order the fdData by acquisitionNum to force use of acquisitionNum
    
    ## as unique ID for the spectrum (issue #103). That way we can use
    ## the spIdx (is the index of the spectrum within the file) for
    ## subsetting and extracting.
    if (!all(sort(fdData$acquisitionNum) == fdData$acquisitionNum))
      warning(paste("Unexpected acquisition number order detected.",
                    "Please contact the maintainers or open an issue",
                    "on https://github.com/lgatto/MSnbase.",
                    sep = "\n")) ## see issue #160
    fdData <- fdData[order(fdData$acquisitionNum), ]
    featureDataList <- c(featureDataList, list(fdData))
    ## Fix for #151; would be nice if we could remove that at some point.
    gc()
    mzR::close(msdata)
    rm(msdata)
  }
  ## new in version 1.9.8
  lockEnvironment(assaydata, bindings = TRUE)
  .cacheEnv <- setCacheEnv(list("assaydata" = assaydata,
                                          "hd" = NULL),
                                     level = 0,
                                     lock = TRUE)
  
  ## Create 'MSnProcess' object
  process <- new("MSnProcess",
                 processing = paste0("Data loaded [", date(), "]"),
                 files = files,
                 smoothed = NA)
  ## Create 'fdata' and 'pdata' objects
  if (is.null(pdata)) {
    .pd <- data.frame(sampleNames = basename(files))
    rownames(.pd) <- .pd$sampleNames
    pdata <- new("AnnotatedDataFrame",
                 data = .pd)
  }
  ## If we've got a featureDataList, use it
  if (length(featureDataList) > 0) {
    fdata <- do.call(rbind, featureDataList)
    fdata <- cbind(fdata, spectrum = 1:nrow(fdata),
                   stringsAsFactors = FALSE)
    ## Setting rownames on the data.frame not on the AnnotatedDataFrame;
    ## did get strange errors otherwise.
    rownames(fdata) <- fullhdorder
    ## Re-order them
    fdata <- fdata[base::sort(fullhdorder), ]
    fdata <- new("AnnotatedDataFrame", data = fdata)
    ## Re-order the features.
    ## fdata <- fdata[ls(assaydata), ]
  } else fdata <- new("AnnotatedDataFrame")
  
  ## expriment data slot
  if (length(.instrumentInfo) > 1) {
    cmp <- length(unique(sapply(.instrumentInfo, "[[", 1)))
    if (cmp > 1)
      message("According to the instrument information in the files,\n",
              "the data has been acquired on different instruments!")
    for (nm in names(.instrumentInfo[[1]]))
      .instrumentInfo[[1]][[nm]] <- sapply(.instrumentInfo, "[[", nm)
  }
  expdata <- new("MIAPE",
                 instrumentManufacturer = .instrumentInfo[[1]]$manufacturer,
                 instrumentModel = .instrumentInfo[[1]]$model,
                 ionSource = .instrumentInfo[[1]]$ionisation,
                 analyser = as.character(.instrumentInfo[[1]]$analyzer),
                 detectorType = .instrumentInfo[[1]]$detector)
  ## Create ProcessingStep if needed.
  ## Create the OnDiskMSnExp object.
  res <- new("OnDiskMSnExp",
             assayData = assaydata,
             phenoData = pdata,
             featureData = fdata,
             processingData = process,
             experimentData = expdata,
             .cache  =  .cacheEnv)
  if (!is.null(msLevel.)) {
    msLevel. <- as.integer(msLevel.)
    res <- filterMsLevel(res, msLevel.)
  }
  if (any(!is.na(centroided.))) {
    if (length(centroided.) == 1) {
      centroided(res) <- centroided.
    } else {
      for (i in seq_along(centroided.))
        centroided(res, msLevel. = i) <- centroided.[i]
    }
  }
  
  if (.on.public.web){
    write.table("Raw file initialized Successfully!",file="metaboanalyst_spec_proc.txt",append = TRUE,row.names = FALSE,col.names = FALSE, quote = FALSE, eol = "\n");
  }
  
  return(res)
}

#' UpdateRawfiles
#' @description Update the Raw spectra included for Processing. All wrong format and uncentroided files will be filtered. 
#' NOTE: this function is only effective before data import stage.
#' @param mSet mSet objects generated with \"mSet<-InitDataObjects(\"spec\", \"raw\", FALSE)\";
#' @param filesIncluded filesIncluded is a vector containing the files' paths for the following processing;
#' @author Zhiqiang Pang \email{zhiqiang.pang@mail.mcgill.ca} and Jeff Xia \email{jeff.xia@mcgill.ca}
#' McGill University, Canada
#' License: GNU GPL (>= 2)
#' @export
#' @examples 
#' ## load googledrive package to download example data
#' # library("googledrive");
#' # data_folder_Sample <- "Raw_data_example"
#' # temp <- tempfile(fileext = ".zip");
#' ## Please authorize the package to download the data from web
#' # dl <- drive_download(as_id("1CjEPed1WZrwd5T3Ovuic1KVF-Uz13NjO"), path = temp, overwrite = TRUE);
#' # out <- unzip(temp, exdir = data_folder_Sample);
#' # out;
#' # library(OptiLCMS);
#' # mSet<-InitDataObjects("spec", "raw", FALSE);
#' ## include only two samples CD_SM-77FXR.mzML and CD_SM-6KUCT.mzML for data import.
#' # mSet<-UpdateRawfiles(mSet, c("Raw_data_example/CD/CD_SM-77FXR.mzML", 
#' #                      "Raw_data_example/CD/CD_SM-6KUCT.mzML"))

UpdateRawfiles <- function(mSet, filesIncluded = NULL){
  
  # TODO: to develope a shiny interface for user to select their files to include
  # if (interactive()) {
  #   
  #   options(shiny.maxRequestSize=400*1024^2) 
  #   
  #   ui <- fluidPage(
  #     titlePanel("Multiple Spectral file read"),
  #     sidebarLayout(
  #       sidebarPanel(
  #         fileInput("SpectralFiles", "Choose Spectra File", accept = c(".mzML",".mzXML","mzml","mzxml","mzData"),
  #                   multiple = TRUE),
  #         
  #       ),
  #       mainPanel(
  #         textOutput("count")
  #       )
  #     )
  #   )
  # 
  #   server <- function(input, output) {
  # 
  #     output$contents <- renderTable({
  #       file <- input$SpectralFiles
  #       ext <- tools::file_ext(file$datapath)
  # 
  #       req(file)
  #       validate(need(ext %in% c(".mzML",".mzXML","mzml","mzxml","mzData"), "Please upload a spectral file !"))
  # 
  #       file;
  #     })
  #     
  #     return(output)
  #   }
  #   
  #   shinyApp(ui, server)
  # }
  
  if(!is.null(filesIncluded)){
    
    # file exits check
    fileIdx <- file.exists(filesIncluded);
    if(!any(fileIdx)){
      stop("No valid files provided ! Please check !")
    }
    filesIncluded_exited <- filesIncluded[fileIdx];
    filesIncluded_full <- unname(sapply(filesIncluded_exited, tools::file_path_as_absolute));
    
    # file format check
    exts <- tools::file_ext(filesIncluded_full);
    extsIdx <- exts %in% c("mzML","mzXML","mzml","mzxml","mzData", "mzdata");
    if(!any(extsIdx)){
      stop("No valid format files provided ! Only files with extension of \"mzML\", \"mzml\", \"mzXML\", \"mzxml\", \"mzData\" and \"mzdata\" are supported!")
    }
    filesIncluded_formated <- filesIncluded_full[extsIdx];
    
    # file centroid check
    Centroididx <- unname(sapply(filesIncluded_formated, CentroidCheck));
    if(!any(Centroididx)){
      stop("No centroided spectrum found ! Please Centroid them first !")
    }
    filesIncluded_centroided <- filesIncluded_formated[Centroididx];
    message(paste0(filesIncluded_centroided, "will be included for further processing !"))
    
    # file size check
    fileSizeInfo <- file.size(filesIncluded_centroided)/1024^2;
    largeFileIdx <- fileSizeInfo > 200;
    if(any(fileSizeInfo)){
      message(paste0(filesIncluded_centroided[largeFileIdx]), "is larger than 200MB, please note your memory !")
    }
    
    filesIncluded <- filesIncluded_centroided;
    
  } else {
    warning("No files will be included for mSet !")
  }
  
  
  if(is.null(filesIncluded)){
    message("No files will be used to update the files inclusion for mSet!")
  }
  
  mSet@rawfiles <- filesIncluded;
  
  if(.on.public.web){
    save(mSet, file = "mSet.rda");
  }
  
  return(mSet);
}

#' Verify the data is centroid or not
#' @param filename single file name, should contain the absolute path
#' @author Zhiqiang Pang \email{zhiqiang.pang@mail.mcgill.ca} and Jeff Xia \email{jeff.xia@mcgill.ca}
#' McGill University, Canada
#' License: GNU GPL (>= 2)
#' @importFrom stats quantile
#' @export
#' @examples  
#' DataFiles <- dir(system.file("mzData", package = "mtbls2"), full.names = TRUE,
#'                  recursive = TRUE)[c(10:12, 14:16)]
#' sapply(DataFiles, CentroidCheck)

CentroidCheck <- function(filename) {
  # fileh <- MSnbase:::.openMSfile(filename)
  fileh <- mzR::openMSfile(filename, backend = NULL)
  allSpect <- mzR::peaks(fileh, c(1:10))
  
  nValues <- base::lengths(allSpect, use.names = FALSE) / 2

  mzR::close(fileh)
  rm(fileh)
  
  res <- lapply(
    allSpect,
    FUN = function(z, APPLF, ...) {
      pk <- as.data.frame(z)
      
      k = 0.025
      qtl = 0.9
      .qtl <- quantile(pk[, 2], qtl)
      x <- pk[pk[, 2] > .qtl, 1]
      quantile(diff(x), 0.25) > k
      
    }
  )
  
  res <- unlist(res[!is.na(res)]);
  return(sum(res) > 0.8*length(res))
  
}

Path2Files <- function(path){
  Pathname <- normalizePath(path);
  
  if (length(Pathname) > 1){
    multipleMS <- TRUE;
  } else {
    multipleMS <- FALSE;
  };
  
  SingleFolder <- SingleFile <- MultiFolder <- MultiFile <- FALSE;
  if(!multipleMS){
    # one character provided!
    if(dir.exists(Pathname)){
      SingleFolder <- TRUE;
    } else if(file.exists(Pathname)) {
      SingleFile <- TRUE;
    } else {
      stop("Invalid path provided, please check!")
    }
  } else {
    # one vector provided!
    if(all(sapply(Pathname, dir.exists))){
      MultiFolder <- TRUE;
    } else if(all(sapply(Pathname, file.exists))){
      MultiFile <- TRUE;
    } else {
      stop("Mixed or Invalid filepath type included, please check!")
    }
    
  }
  
  if(.on.public.web){
    if (!dir.exists(Pathname)) {
      Pathname <- "/home/glassfish/projects/MetaboDemoRawData/upload"
    }
  }
  
  pathnames <- unname(unlist(sapply(Pathname, tools::file_path_as_absolute)));
  
  if(SingleFile | MultiFile){
    
    files_tmp <- pathnames;
    
  } else {
    
    files_tmp <-
      dir(
        pathnames,
        pattern = ".mzML|.mzml|.cdf|.mzXML|.mzxml|.mzData|.CDF",
        recursive = TRUE,
        full.names = TRUE
      );
    
  }
  
  files_exts <- tools::file_ext(files_tmp);
  if(length(unique(files_exts)) > 1){
    stop("Multiple data formats are not allowed!")
  };
  
  formatRes <- files_exts %in% c("mzML","mzml","cdf","mzXML","mzxml","mzData","CDF");
  
  if(!all(formatRes)){
    warning("Wrong file format detected, Only mzML, mzXML, mzData or CDF will be included.")
  }
  
  files <- files_tmp[formatRes];
  
  # Centroid check & filter
  Centroididx <- unname(sapply(files, CentroidCheck));
  
  if(!all(Centroididx)){
    warning(paste0("Uncentroieded file: ", basename(files[!Centroididx]), "will be filtered!\n"))
  }
  
  files <- files[Centroididx];
  return(files)
}

#' @references Gatto L, Gibb S, Rainer J (2020). “MSnbase, efficient and elegant R-based processing and visualisation of raw mass spectrometry data.” bioRxiv.
.testReadMSDataInput <- function(e) {
  if (is.numeric(e$msLevel) && !all(e$msLevel > 0))
    stop("msLevel must be an integer > 0.")
  if (length(e$files) < 1)
    stop("At least one MS file is required.")
  if (all(unique(e$files) != e$files))
    stop("Non unique files provided as input. ")
  extensions <- unique(toupper(sub("^.+\\.", "", e$files)))
  if (length(extensions) > 1)
    warning(paste("Reading different file formats in.",
                  "This is untested and you are welcome to try it out.",
                  "Please report back!", sep = "\n"))
  invisible(TRUE)
}
testCacheArg <- function(cache, maxCache = 2) {
  ## Function used to test the value of a 'cache'
  ## parameter in a read*Data function
  ## Parameters:
  ##  cache: value of the cache argument to test
  ##  maxCache: max value allowed. Generally
  ##            3, but could be less, depending
  ##            on the input data. maxCache is 1
  ##            for readMgfData for instance.
  ## Value: valid (possibly updated) cache value
  if (!is.numeric(cache))
    stop("'cache' must be numeric.")
  if (cache < 0 | cache > maxCache) {
    warning("cache must be [0:", maxCache, "]!")
    if (cache < 0) {
      warning("Setting cache to 0.")
      cache <- 0
    } else {
      warning("Setting cache to ", maxCache, ".")
      cache <- maxCache
    }
  }
  return(cache)
}
setCacheEnv <- function(toCache, level = 0, lock = TRUE) {
  ## Set the .cache slot of a pSet object.
  ## Parameters
  ##  toCache a list with
  ##     "assaydata": environment - pSet assaydata slot
  ##     "hd": header dataframe
  ##  level: numeric - cache level
  ##  lock: logical - lock env and bindings (default is TRUE)
  ## Return:
  ##  A new cache environment
  level <- testCacheArg(level)
  cacheEnv <- new.env(parent = emptyenv())
  assaydata <- toCache[["assaydata"]]
  hd <- toCache[["hd"]]
  assign("level", level, cacheEnv)
  if (level >= 1) { ## levels 2 and 3 not yet implemented
    ## precursor MZ
    precMz <- unname(eapply(assaydata, precursorMz))
    assign("rangePrecursorMz", range(precMz), cacheEnv)
    assign("nPrecursorMz", length(precMz), cacheEnv)
    assign("uPrecursorMz", length(unique(precMz)), cacheEnv)
    ## MS2 MS range
    assign("rangeMz", range(unname(eapply(assaydata, mz))),
           cacheEnv)
    ## MS2 retention time
    Rtime <- unname(eapply(assaydata, rtime))
    assign("rangeRtime", range(Rtime), cacheEnv)
    assign("nRtime", length(Rtime), cacheEnv)
    ## MS levels
    assign("msLevels", unique(unlist(eapply(assaydata, msLevel))),
           cacheEnv)
    ## precursor scans
    assign("nPrecursorScans",
           length(unique(eapply(assaydata, precScanNum))), cacheEnv)
    ## assay data size
    assign("size",
           sum(unlist(unname(eapply(assaydata, object.size)))),
           cacheEnv)
    ## full header
    assign("hd", hd, cacheEnv)
  }
  if (lock)
    lockEnvironment(cacheEnv, bindings = TRUE)
  return(cacheEnv)
}
isCdfFile <- function(x) {
  fileEnds <- c("cdf", "nc")
  ## check for endings and and ending followed by a . (e.g. cdf.gz)
  patts <- paste0("\\.", fileEnds, "($|\\.)")
  res <- sapply(patts, function(z) {
    grep(z, x, ignore.case = TRUE)
  })
  return(any(unlist(res)))
}
formatFileSpectrumNames <- function(fileIds, spectrumIds,
                                    nFiles=length(fileIds),
                                    nSpectra=length(spectrumIds)) {
  digits <- ceiling(log10(c(nFiles, nSpectra) + 1L))
  
  if (length(fileIds) != 1L && length(spectrumIds) != length(fileIds)) {
    stop("Length of 'fileIds' has to be one or equal to ",
         "the length of 'spectrumIds'.")
  }
  
  sprintf(paste0("F%0", digits[1L], "d.S%0", digits[2L], "d"),
          fileIds, spectrumIds)
}